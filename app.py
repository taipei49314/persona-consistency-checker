
import streamlit as st
import json
import yaml
from src.utils import normalize_text, compute_similarity, check_speech_patterns
from datetime import datetime

st.set_page_config(page_title="PersonaChain v2.0", layout="centered")
st.title("ğŸ§  PersonaChain v2.0ï½œèªè¨€äººæ ¼åˆ†æå™¨")

# ç¶½è™Ÿè¼¸å…¥å€ï¼ˆè§’è‰²è­˜åˆ¥ï¼‰
nickname = st.text_input("è«‹è¼¸å…¥ä½ çš„ç¶½è™Ÿ / Your Persona Nickname", max_chars=20)

if nickname:
    st.success(f"ğŸ‘¤ ç›®å‰åˆ†æè§’è‰²ï¼š{nickname}")

    lang = st.selectbox("è«‹é¸æ“‡èªè¨€ / Select Language", ["zh", "en", "ja", "ko"], index=0)

    persona_file = f"data/base_persona_{lang}.json"
    pattern_file = f"data/patterns_{lang}.yaml"

    with open(persona_file, "r", encoding="utf-8") as f:
        persona = json.load(f)

    with open(pattern_file, "r", encoding="utf-8") as f:
        pattern_data = yaml.safe_load(f)
        pattern_hits = pattern_data.get("patterns", [])

    st.markdown("è«‹è¼¸å…¥ä¸€å¥æˆ–å¤šå¥è©±ï¼ˆæ¯è¡Œä¸€å¥ï¼‰ï¼š")

    multi_input = st.text_area("èªå¥è¼¸å…¥å€ / Input Zone", height=200)

    if multi_input:
        st.divider()
        st.markdown("## åˆ†æçµæœ / Analysis Result")
        lines = [line.strip() for line in multi_input.strip().splitlines() if line.strip()]
        drift_count = 0
        total_score = 0
        records = []

        for i, utt in enumerate(lines, 1):
            utt_norm = normalize_text(utt)
            sim_score = compute_similarity(utt_norm, persona)
            matched = [kw for kw in pattern_hits if kw in utt_norm]
            inconsistent = sim_score < 0.5
            drift_count += int(inconsistent)
            total_score += sim_score

            records.append({
                "nickname": nickname,
                "sentence": utt,
                "language": lang,
                "score": round(sim_score, 3),
                "patterns_hit": matched,
                "drift": inconsistent,
                "timestamp": datetime.now().isoformat()
            })

            st.markdown(f"### âœï¸ ç¬¬ {i} å¥ / Sentence {i}")
            st.markdown(f"- èªå¥ / Text: `{utt}`")
            st.progress(sim_score, text=f"ä¸€è‡´æ€§åˆ†æ•¸ / Score: {sim_score:.2f}")
            st.markdown(f"- å‘½ä¸­èªæ°£ç‰¹å¾µ / Patterns: `{matched}`")
            st.markdown(f"- åˆ¤å®šçµæœ / Consistency: {'âŒ åé›¢ / Drift' if inconsistent else 'âœ… ä¸€è‡´ / Consistent'}")
            st.markdown("---")

        avg_score = total_score / len(lines)
        lang_summary = {
            "zh": f"ğŸ§  ç¸½é«”ä¸€è‡´æ€§åˆ†æ•¸ï¼š{avg_score:.2f} ï¼ åé›¢å¥æ•¸ï¼š{drift_count} ï¼ å…± {len(lines)} å¥",
            "en": f"ğŸ§  Overall consistency score: {avg_score:.2f} ï¼ {drift_count} drifted out of {len(lines)} sentences",
            "ja": f"ğŸ§  ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ï¼š{avg_score:.2f} ï¼ {len(lines)} æ–‡ã®ã†ã¡ {drift_count} æ–‡ãŒé€¸è„±",
            "ko": f"ğŸ§  ì¼ê´€ì„± ì ìˆ˜: {avg_score:.2f} ï¼ ì´ {len(lines)}ë¬¸ ì¤‘ {drift_count}ë¬¸ ì¼íƒˆ"
        }
        st.success(lang_summary[lang])

        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰æœ¬æ¬¡èªå¥åˆ†æçµæœï¼ˆJSONï¼‰",
            data=json.dumps(records, ensure_ascii=False, indent=2),
            file_name=f"{nickname}_persona_records.json",
            mime="application/json"
        )
else:
    st.warning("è«‹å…ˆè¼¸å…¥ä½ çš„ç¶½è™Ÿæ‰èƒ½é–‹å§‹åˆ†æ / Please enter your nickname.")
